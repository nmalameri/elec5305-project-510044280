# Headline Results (ASVspoof 2019 LA)

This file summarises headline performance for all four systems evaluated on the
ASVspoof 2019 Logical Access protocol, using the DEV-set EER threshold.

The metrics correspond to the values generated by `08_collect_results.py`.

---

## ðŸ”¢ Summary Table

| System       | Dev EER (%) | Eval EER (%) | Eval ACC (%) |
|--------------|-------------|--------------|--------------|
| **LFCC + GMM** | 0.58        | 9.30         | 78.49        |
| **MFCC + GMM** | 9.96        | 12.51        | 84.12        |
| **LFCC + CNN** | 0.01        | 12.31        | 64.62        |
| **MFCC + CNN** | 14.64       | 20.30        | 76.36        |

---

## ðŸ“Œ Interpretation

- **LFCC + GMM** achieves the best EVAL EER (9.30%), showing superior robustness.
- **MFCC + GMM** achieves the highest accuracy (84.12%) but with a higher EER.
- CNN models show strong DEV performance but weaker generalisation on EVAL.
- The results align with known ASVspoof trends: simple generative models can outperform neural models on mismatched conditions.

These headline scores match the main results reported in the project report and README.